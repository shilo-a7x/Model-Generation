{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models import IrisClassifier\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.33\n",
    ")\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    torch.tensor(X_train, device=device, dtype=torch.float32),\n",
    "    torch.tensor(X_test, device=device, dtype=torch.float32),\n",
    "    torch.tensor(y_train, device=device, dtype=torch.long),\n",
    "    torch.tensor(y_test, device=device, dtype=torch.long),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import namedtuple\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "ModelInfo = namedtuple(\"ModelInfo\", [\"state_dict\", \"matrix\"])\n",
    "\n",
    "def train_model(train_loader: DataLoader):\n",
    "    model = IrisClassifier().to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "    model.train()\n",
    "    num_epochs = 200\n",
    "    for _ in range(num_epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "    W = model.linear.weight.data\n",
    "    b = model.linear.bias.data\n",
    "    b = b.view(-1, 1)\n",
    "    Wb_matrix = torch.cat((W, b), dim=1)\n",
    "    return ModelInfo(state_dict=model.state_dict(), matrix=Wb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 49 models\n",
      "trained 99 models\n",
      "trained 149 models\n",
      "trained 199 models\n",
      "trained 249 models\n",
      "trained 299 models\n",
      "trained 349 models\n",
      "trained 399 models\n",
      "trained 449 models\n",
      "trained 499 models\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "NUM_OF_MODELS = 500\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "real_models = []\n",
    "for i in range(NUM_OF_MODELS):\n",
    "    model_info = train_model(train_loader)\n",
    "    real_models.append(model_info)\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(\"trained {} models\".format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained 50 models\n",
      "trained 100 models\n",
      "trained 150 models\n",
      "trained 200 models\n",
      "trained 250 models\n",
      "trained 300 models\n",
      "trained 350 models\n",
      "trained 400 models\n",
      "trained 450 models\n",
      "trained 500 models\n"
     ]
    }
   ],
   "source": [
    "scrambled_models = []\n",
    "for i in range(NUM_OF_MODELS):\n",
    "    scramble_indices = torch.randperm(y_train.size(0), device=device)\n",
    "    y_train_scrambled = y_train[scramble_indices]\n",
    "\n",
    "    train_dataset_scrambled = TensorDataset(X_train, y_train_scrambled)\n",
    "    train_loader_scrambled = DataLoader(\n",
    "        train_dataset_scrambled, batch_size=16, shuffle=True\n",
    "    )\n",
    "    model_info = train_model(train_loader_scrambled)\n",
    "    scrambled_models.append(model_info)\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(\"trained {} models\".format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scrambled models\n",
      "Saved trained models\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "edit_pickle = False\n",
    "\n",
    "real_matrix_list = [real.matrix for real in real_models]\n",
    "scrambled_matrix_list = [s.matrix for s in scrambled_models]\n",
    "\n",
    "if edit_pickle == True:\n",
    "    with open('scrambled_matrix_list.pickle', 'wb') as f:\n",
    "        pickle.dump(scrambled_matrix_list, f)\n",
    "        print(\"Saved scrambled models\")\n",
    "\n",
    "    with open('real_matrix_list.pickle', 'wb') as f:\n",
    "        pickle.dump(real_matrix_list, f)\n",
    "        print(\"Saved trained models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
