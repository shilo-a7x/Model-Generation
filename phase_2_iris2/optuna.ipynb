{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from model import Iris2LayerClassifier\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim_w1,\n",
    "        input_dim_w2,\n",
    "        hidden_dims_encoder,\n",
    "        hidden_dims_decoder,\n",
    "        z_dim=32,\n",
    "        use_batchnorm=True,\n",
    "    ):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        encoder_layers = []\n",
    "        in_dim = input_dim_w2\n",
    "        for out_dim in hidden_dims_encoder:\n",
    "            encoder_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if use_batchnorm:\n",
    "                encoder_layers.append(nn.BatchNorm1d(out_dim))\n",
    "            encoder_layers.append(nn.ReLU())\n",
    "            in_dim = out_dim\n",
    "        self.encoder_nn1 = nn.Sequential(*encoder_layers)\n",
    "\n",
    "        encoder_layers = []\n",
    "        in_dim = input_dim_w1 + hidden_dims_encoder[-1]\n",
    "        for out_dim in hidden_dims_encoder:\n",
    "            encoder_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if use_batchnorm:\n",
    "                encoder_layers.append(nn.BatchNorm1d(out_dim))\n",
    "            encoder_layers.append(nn.ReLU())\n",
    "            in_dim = out_dim\n",
    "        self.encoder_nn2 = nn.Sequential(*encoder_layers)\n",
    "\n",
    "        self.fc_mu = nn.Linear(hidden_dims_encoder[-1], z_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dims_encoder[-1], z_dim)\n",
    "\n",
    "        decoder_layers = []\n",
    "        in_dim = z_dim\n",
    "        for out_dim in hidden_dims_decoder:\n",
    "            decoder_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if use_batchnorm:\n",
    "                decoder_layers.append(nn.BatchNorm1d(out_dim))\n",
    "            decoder_layers.append(nn.ReLU())\n",
    "            in_dim = out_dim\n",
    "        self.decoder_nn3 = nn.Sequential(*decoder_layers)\n",
    "        self.decoder_nn3.add_module(\n",
    "            \"output\", nn.Linear(hidden_dims_decoder[-1], input_dim_w1)\n",
    "        )\n",
    "\n",
    "        decoder_layers = []\n",
    "        in_dim = z_dim + input_dim_w1\n",
    "        for out_dim in hidden_dims_decoder:\n",
    "            decoder_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if use_batchnorm:\n",
    "                decoder_layers.append(nn.BatchNorm1d(out_dim))\n",
    "            decoder_layers.append(nn.ReLU())\n",
    "            in_dim = out_dim\n",
    "        self.decoder_nn4 = nn.Sequential(*decoder_layers)\n",
    "        self.decoder_nn4.add_module(\n",
    "            \"output\", nn.Linear(hidden_dims_decoder[-1], input_dim_w2)\n",
    "        )\n",
    "\n",
    "    def encode(self, w1, w2):\n",
    "        h1 = self.encoder_nn1(w2)\n",
    "        h2 = self.encoder_nn2(torch.cat((w1, h1), dim=1))\n",
    "        mu = self.fc_mu(h2)\n",
    "        logvar = self.fc_logvar(h2)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        weight1_hat = self.decoder_nn3(z)\n",
    "        weight2_hat = self.decoder_nn4(torch.cat((z, weight1_hat), dim=1))\n",
    "        return weight1_hat, weight2_hat\n",
    "\n",
    "    def forward(self, w1, w2):\n",
    "        mu, logvar = self.encode(w1, w2)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        weight1_hat, weight2_hat = self.decode(z)\n",
    "        return weight1_hat, weight2_hat, mu, logvar\n",
    "\n",
    "\n",
    "def loss_function(weight1_hat, weight2_hat, weight1, weight2, mu, logvar):\n",
    "    recon_loss1 = F.mse_loss(weight1_hat, weight1, reduction=\"sum\")\n",
    "    recon_loss2 = F.mse_loss(weight2_hat, weight2, reduction=\"sum\")\n",
    "    recon_loss = recon_loss1 + recon_loss2\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == \"torch.storage\" and name == \"_load_from_bytes\":\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location=\"cpu\")\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "\n",
    "with open(\"2_layer_real_models.pickle\", \"rb\") as f:\n",
    "    real_models = CPU_Unpickler(f).load()\n",
    "\n",
    "\n",
    "class WeightsDataset(Dataset):\n",
    "    def __init__(self, state_dicts):\n",
    "        self.data = [self.flatten_state_dict(sd) for sd in state_dicts]\n",
    "        self.data = self.global_normalize(self.data)\n",
    "\n",
    "    def flatten_state_dict(self, state_dict):\n",
    "        weight1 = state_dict[\"classifier.0.weight\"].view(-1)\n",
    "        bias1 = state_dict[\"classifier.0.bias\"].view(-1)\n",
    "        weight2 = state_dict[\"classifier.2.weight\"].view(-1)\n",
    "        bias2 = state_dict[\"classifier.2.bias\"].view(-1)\n",
    "        flattened_w1 = torch.cat([weight1, bias1])\n",
    "        flattened_w2 = torch.cat([weight2, bias2])\n",
    "        return flattened_w1, flattened_w2\n",
    "\n",
    "    def global_normalize(self, data):\n",
    "        all_w1 = torch.cat([w1 for w1, _ in self.data])\n",
    "        all_w2 = torch.cat([w2 for _, w2 in self.data])\n",
    "        all = torch.cat([all_w1, all_w2])\n",
    "        min, max = all.min(), all.max()\n",
    "        data = [\n",
    "            (self.minmax(w1, min, max), self.minmax(w2, min, max))\n",
    "            for w1, w2 in self.data\n",
    "        ]\n",
    "        mean, std = all.mean(), all.std()\n",
    "        data = [\n",
    "            (self.normalize(w1, mean, std), self.normalize(w2, mean, std))\n",
    "            for w1, w2 in self.data\n",
    "        ]\n",
    "        return data\n",
    "\n",
    "    def minmax(self, data, min, max):\n",
    "        return (2 * (data - min)) / (max - min) - 1\n",
    "\n",
    "    def normalize(self, data, mean, std):\n",
    "        return (data - mean) / std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "train_dataset = WeightsDataset(real_models)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "sample = train_dataset[0]\n",
    "w1_size, w2_size = sample[0].size()[0], sample[1].size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.33\n",
    ")\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    torch.tensor(X_train, device=device, dtype=torch.float32),\n",
    "    torch.tensor(X_test, device=device, dtype=torch.float32),\n",
    "    torch.tensor(y_train, device=device, dtype=torch.long),\n",
    "    torch.tensor(y_test, device=device, dtype=torch.long),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hidden_dims_encoder = [\n",
    "        trial.suggest_int(f\"hidden_dim_enc_{i}\", 16, 128)\n",
    "        for i in range(trial.suggest_int(\"num_layers_encoder\", 1, 4))\n",
    "    ]\n",
    "    hidden_dims_decoder = [\n",
    "        trial.suggest_int(f\"hidden_dim_dec_{i}\", 16, 128)\n",
    "        for i in range(trial.suggest_int(\"num_layers_decoder\", 1, 4))\n",
    "    ]\n",
    "    z_dim = trial.suggest_int(\"z_dim\", 8, 64)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\n",
    "    epochs = trial.suggest_int(\"epochs\", 50, 500)\n",
    "    use_batchnorm = trial.suggest_categorical(\"use_batchnorm\", [True, False])\n",
    "\n",
    "    vae = VAE(\n",
    "        input_dim_w1=w1_size,\n",
    "        input_dim_w2=w2_size,\n",
    "        hidden_dims_encoder=hidden_dims_encoder,\n",
    "        hidden_dims_decoder=hidden_dims_decoder,\n",
    "        z_dim=z_dim,\n",
    "        use_batchnorm=use_batchnorm,\n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(vae.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        vae.train()\n",
    "        train_loss = 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            batch_w1, batch_w2 = batch[0], batch[1]\n",
    "            weight1_hat, weight2_hat, mu, logvar = vae(batch_w1, batch_w2)\n",
    "            loss = loss_function(\n",
    "                weight1_hat, weight2_hat, batch_w1, batch_w2, mu, logvar\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        avg_loss = train_loss / len(train_loader.dataset)\n",
    "        losses.append(avg_loss)\n",
    "        trial.report(avg_loss, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    NUM_OF_MODELS = 500\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(NUM_OF_MODELS, z_dim).to(device)\n",
    "        vae.eval()\n",
    "        weight1_hats, weight2_hats = vae.decode(z)\n",
    "\n",
    "    temp_model = Iris2LayerClassifier()\n",
    "    weight1_shape = temp_model.classifier[0].weight.shape\n",
    "    bias1_shape = temp_model.classifier[0].bias.shape\n",
    "    weight2_shape = temp_model.classifier[2].weight.shape\n",
    "    bias2_shape = temp_model.classifier[2].bias.shape\n",
    "    w1_len = torch.prod(torch.tensor(weight1_shape)).item()\n",
    "    w2_len = torch.prod(torch.tensor(weight2_shape)).item()\n",
    "    generated_models = []\n",
    "    for i in range(NUM_OF_MODELS):\n",
    "        weight1_hat = weight1_hats[i]\n",
    "        weight2_hat = weight2_hats[i]\n",
    "        w1 = weight1_hat[:w1_len].view(weight1_shape)\n",
    "        b1 = weight1_hat[w1_len:].view(bias1_shape)\n",
    "        w2 = weight2_hat[:w2_len].view(weight2_shape)\n",
    "        b2 = weight2_hat[w2_len:].view(bias2_shape)\n",
    "        new_state_dict = {\n",
    "            \"classifier.0.weight\": w1,\n",
    "            \"classifier.0.bias\": b1,\n",
    "            \"classifier.2.weight\": w2,\n",
    "            \"classifier.2.bias\": b2,\n",
    "        }\n",
    "        generated_models.append(new_state_dict)\n",
    "\n",
    "    accuracies = []\n",
    "    for i, state_dict in enumerate(generated_models):\n",
    "        model = Iris2LayerClassifier().to(device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            y_pred = model(X_test)\n",
    "            _, labels = torch.max(y_pred, 1)\n",
    "            accuracy = accuracy_score(y_test.cpu().numpy(), labels.cpu().numpy())\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "    mean_accuracy = torch.tensor(accuracies).mean().item()\n",
    "    std_accuracy = torch.tensor(accuracies).std().item()\n",
    "\n",
    "    return mean_accuracy - std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-13 14:36:59,124] A new study created in memory with name: no-name-e12117d2-b67b-42dd-9b96-66d4ee853b2c\n",
      "[I 2024-09-13 14:37:10,048] Trial 0 finished with value: 0.6037428773421186 and parameters: {'num_layers_encoder': 2, 'hidden_dim_enc_0': 56, 'hidden_dim_enc_1': 66, 'num_layers_decoder': 2, 'hidden_dim_dec_0': 91, 'hidden_dim_dec_1': 42, 'z_dim': 16, 'lr': 0.004239166411079838, 'weight_decay': 4.945092711569469e-05, 'epochs': 369, 'use_batchnorm': False}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:37:24,874] Trial 1 finished with value: 0.5871435642026036 and parameters: {'num_layers_encoder': 2, 'hidden_dim_enc_0': 114, 'hidden_dim_enc_1': 82, 'num_layers_decoder': 3, 'hidden_dim_dec_0': 49, 'hidden_dim_dec_1': 25, 'hidden_dim_dec_2': 45, 'z_dim': 41, 'lr': 0.00025590262983184615, 'weight_decay': 0.04920107967176251, 'epochs': 282, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:37:48,851] Trial 2 finished with value: 0.24172592053005051 and parameters: {'num_layers_encoder': 4, 'hidden_dim_enc_0': 105, 'hidden_dim_enc_1': 21, 'hidden_dim_enc_2': 111, 'hidden_dim_enc_3': 23, 'num_layers_decoder': 2, 'hidden_dim_dec_0': 113, 'hidden_dim_dec_1': 28, 'z_dim': 59, 'lr': 1.3493658835261276e-05, 'weight_decay': 0.0028670236721466315, 'epochs': 406, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:37:53,852] Trial 3 finished with value: 0.45675872267024187 and parameters: {'num_layers_encoder': 1, 'hidden_dim_enc_0': 16, 'num_layers_decoder': 1, 'hidden_dim_dec_0': 108, 'z_dim': 21, 'lr': 8.157162859971385e-05, 'weight_decay': 0.05130980192375024, 'epochs': 185, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:38:07,456] Trial 4 finished with value: 0.5681595427987972 and parameters: {'num_layers_encoder': 2, 'hidden_dim_enc_0': 122, 'hidden_dim_enc_1': 113, 'num_layers_decoder': 1, 'hidden_dim_dec_0': 63, 'z_dim': 14, 'lr': 0.010719175522821547, 'weight_decay': 0.00105610365905897, 'epochs': 403, 'use_batchnorm': False}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:38:07,499] Trial 5 pruned. \n",
      "[I 2024-09-13 14:38:07,558] Trial 6 pruned. \n",
      "[I 2024-09-13 14:38:07,589] Trial 7 pruned. \n",
      "[I 2024-09-13 14:38:07,625] Trial 8 pruned. \n",
      "[I 2024-09-13 14:38:20,963] Trial 9 finished with value: 0.38 and parameters: {'num_layers_encoder': 3, 'hidden_dim_enc_0': 121, 'hidden_dim_enc_1': 95, 'hidden_dim_enc_2': 71, 'num_layers_decoder': 2, 'hidden_dim_dec_0': 57, 'hidden_dim_dec_1': 105, 'z_dim': 19, 'lr': 0.06895360254192724, 'weight_decay': 0.06231884902224378, 'epochs': 356, 'use_batchnorm': False}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:38:21,041] Trial 10 pruned. \n",
      "[I 2024-09-13 14:38:36,641] Trial 11 finished with value: 0.4110189910203607 and parameters: {'num_layers_encoder': 3, 'hidden_dim_enc_0': 56, 'hidden_dim_enc_1': 70, 'hidden_dim_enc_2': 19, 'num_layers_decoder': 4, 'hidden_dim_dec_0': 87, 'hidden_dim_dec_1': 17, 'hidden_dim_dec_2': 22, 'hidden_dim_dec_3': 21, 'z_dim': 38, 'lr': 0.00022059305628509575, 'weight_decay': 0.00013958777286913926, 'epochs': 253, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:38:36,736] Trial 12 pruned. \n",
      "[I 2024-09-13 14:38:36,841] Trial 13 pruned. \n",
      "[I 2024-09-13 14:38:36,941] Trial 14 pruned. \n",
      "[I 2024-09-13 14:38:37,041] Trial 15 pruned. \n",
      "[I 2024-09-13 14:38:37,141] Trial 16 pruned. \n",
      "[I 2024-09-13 14:38:58,673] Trial 17 finished with value: 0.591329114231532 and parameters: {'num_layers_encoder': 2, 'hidden_dim_enc_0': 33, 'hidden_dim_enc_1': 51, 'num_layers_decoder': 3, 'hidden_dim_dec_0': 45, 'hidden_dim_dec_1': 126, 'hidden_dim_dec_2': 29, 'z_dim': 40, 'lr': 0.00040153615578518794, 'weight_decay': 0.0016582673873607177, 'epochs': 428, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:38:58,780] Trial 18 pruned. \n",
      "[I 2024-09-13 14:38:58,864] Trial 19 pruned. \n",
      "[I 2024-09-13 14:38:58,943] Trial 20 pruned. \n",
      "[I 2024-09-13 14:39:17,128] Trial 21 finished with value: 0.5894779982848086 and parameters: {'num_layers_encoder': 2, 'hidden_dim_enc_0': 67, 'hidden_dim_enc_1': 62, 'num_layers_decoder': 3, 'hidden_dim_dec_0': 51, 'hidden_dim_dec_1': 48, 'hidden_dim_dec_2': 44, 'z_dim': 40, 'lr': 0.00036430466334013464, 'weight_decay': 0.008257341543996892, 'epochs': 381, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:39:17,233] Trial 22 pruned. \n",
      "[I 2024-09-13 14:39:44,217] Trial 23 finished with value: 0.5675767904864295 and parameters: {'num_layers_encoder': 2, 'hidden_dim_enc_0': 60, 'hidden_dim_enc_1': 57, 'num_layers_decoder': 4, 'hidden_dim_dec_0': 73, 'hidden_dim_dec_1': 67, 'hidden_dim_dec_2': 59, 'hidden_dim_dec_3': 25, 'z_dim': 44, 'lr': 0.0004693651022454727, 'weight_decay': 0.0015469640117759188, 'epochs': 473, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:40:07,564] Trial 24 finished with value: 0.3511787915924677 and parameters: {'num_layers_encoder': 3, 'hidden_dim_enc_0': 34, 'hidden_dim_enc_1': 75, 'hidden_dim_enc_2': 97, 'num_layers_decoder': 3, 'hidden_dim_dec_0': 31, 'hidden_dim_dec_1': 77, 'hidden_dim_dec_2': 31, 'z_dim': 63, 'lr': 3.783292498369778e-05, 'weight_decay': 0.003529257867146972, 'epochs': 380, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:40:07,678] Trial 25 pruned. \n",
      "[I 2024-09-13 14:40:07,767] Trial 26 pruned. \n",
      "[I 2024-09-13 14:40:32,891] Trial 27 finished with value: 0.5942601093051804 and parameters: {'num_layers_encoder': 2, 'hidden_dim_enc_0': 63, 'hidden_dim_enc_1': 50, 'num_layers_decoder': 4, 'hidden_dim_dec_0': 77, 'hidden_dim_dec_1': 112, 'hidden_dim_dec_2': 94, 'hidden_dim_dec_3': 73, 'z_dim': 52, 'lr': 0.00017971699612041091, 'weight_decay': 0.019384536897004475, 'epochs': 362, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:40:33,006] Trial 28 pruned. \n",
      "[I 2024-09-13 14:40:47,383] Trial 29 finished with value: 0.31258409073701454 and parameters: {'num_layers_encoder': 1, 'hidden_dim_enc_0': 23, 'num_layers_decoder': 4, 'hidden_dim_dec_0': 65, 'hidden_dim_dec_1': 127, 'hidden_dim_dec_2': 113, 'hidden_dim_dec_3': 74, 'z_dim': 46, 'lr': 3.174922258101808e-05, 'weight_decay': 0.00023999316059439168, 'epochs': 248, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:41:11,295] Trial 30 finished with value: 0.5824196285656399 and parameters: {'num_layers_encoder': 2, 'hidden_dim_enc_0': 62, 'hidden_dim_enc_1': 29, 'num_layers_decoder': 4, 'hidden_dim_dec_0': 99, 'hidden_dim_dec_1': 115, 'hidden_dim_dec_2': 90, 'hidden_dim_dec_3': 107, 'z_dim': 53, 'lr': 0.00015997404180214718, 'weight_decay': 3.202223970980554e-05, 'epochs': 355, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:41:11,432] Trial 31 pruned. \n",
      "[I 2024-09-13 14:41:11,529] Trial 32 pruned. \n",
      "[I 2024-09-13 14:41:11,629] Trial 33 pruned. \n",
      "[I 2024-09-13 14:41:11,753] Trial 34 pruned. \n",
      "[I 2024-09-13 14:41:35,359] Trial 35 finished with value: 0.32348026293654936 and parameters: {'num_layers_encoder': 2, 'hidden_dim_enc_0': 52, 'hidden_dim_enc_1': 44, 'num_layers_decoder': 4, 'hidden_dim_dec_0': 62, 'hidden_dim_dec_1': 30, 'hidden_dim_dec_2': 83, 'hidden_dim_dec_3': 49, 'z_dim': 50, 'lr': 3.170171118956786e-05, 'weight_decay': 0.03641942461157478, 'epochs': 391, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:41:35,442] Trial 36 pruned. \n",
      "[I 2024-09-13 14:41:35,558] Trial 37 pruned. \n",
      "[I 2024-09-13 14:41:48,964] Trial 38 finished with value: 0.5595553255978764 and parameters: {'num_layers_encoder': 1, 'hidden_dim_enc_0': 64, 'num_layers_decoder': 3, 'hidden_dim_dec_0': 53, 'hidden_dim_dec_1': 32, 'hidden_dim_dec_2': 104, 'z_dim': 63, 'lr': 0.00012604851610862168, 'weight_decay': 0.0004902696169721146, 'epochs': 299, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n",
      "[I 2024-09-13 14:41:49,064] Trial 39 pruned. \n",
      "[I 2024-09-13 14:41:49,147] Trial 40 pruned. \n",
      "[I 2024-09-13 14:41:49,264] Trial 41 pruned. \n",
      "[I 2024-09-13 14:41:49,364] Trial 42 pruned. \n",
      "[I 2024-09-13 14:41:49,480] Trial 43 pruned. \n",
      "[I 2024-09-13 14:41:49,613] Trial 44 pruned. \n",
      "[I 2024-09-13 14:41:49,714] Trial 45 pruned. \n",
      "[I 2024-09-13 14:41:49,813] Trial 46 pruned. \n",
      "[I 2024-09-13 14:41:49,880] Trial 47 pruned. \n",
      "[I 2024-09-13 14:41:50,029] Trial 48 pruned. \n",
      "[I 2024-09-13 14:42:06,296] Trial 49 finished with value: 0.3853723591830305 and parameters: {'num_layers_encoder': 3, 'hidden_dim_enc_0': 25, 'hidden_dim_enc_1': 70, 'hidden_dim_enc_2': 128, 'num_layers_decoder': 3, 'hidden_dim_dec_0': 78, 'hidden_dim_dec_1': 32, 'hidden_dim_dec_2': 20, 'z_dim': 50, 'lr': 9.443429404164056e-05, 'weight_decay': 0.09279836983726378, 'epochs': 270, 'use_batchnorm': True}. Best is trial 0 with value: 0.6037428773421186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.6037428773421186\n",
      "  Params: \n",
      "    num_layers_encoder: 2\n",
      "    hidden_dim_enc_0: 56\n",
      "    hidden_dim_enc_1: 66\n",
      "    num_layers_decoder: 2\n",
      "    hidden_dim_dec_0: 91\n",
      "    hidden_dim_dec_1: 42\n",
      "    z_dim: 16\n",
      "    lr: 0.004239166411079838\n",
      "    weight_decay: 4.945092711569469e-05\n",
      "    epochs: 369\n",
      "    use_batchnorm: False\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(f\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
